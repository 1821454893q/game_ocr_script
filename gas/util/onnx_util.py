import onnxruntime as ort
import cv2
import numpy as np
import time
from pathlib import Path
from typing import Union, List, Dict, Optional
import win32gui
import win32ui
import win32con

from gas.logger import get_logger

log = get_logger()


class YOLOONNXDetector:
    """
    YOLO ONNX æ£€æµ‹å™¨ - æ”¯æŒå¤šç§è¾“å…¥æº
    åŠŸèƒ½ï¼šå›¾ç‰‡æ–‡ä»¶ã€numpyæ•°ç»„ã€çª—å£å¥æŸ„æˆªå›¾
    """

    def __init__(
        self,
        onnx_path: str,
        class_names: List[str] = None,
        conf_threshold: float = 0.3,
        iou_threshold: float = 0.5,
        input_size: tuple = (640, 640),
    ):
        """
        åˆå§‹åŒ–æ£€æµ‹å™¨

        Args:
            onnx_path: ONNXæ¨¡å‹æ–‡ä»¶è·¯å¾„
            class_names: ç±»åˆ«åç§°åˆ—è¡¨
            conf_threshold: ç½®ä¿¡åº¦é˜ˆå€¼
            iou_threshold: IOUé˜ˆå€¼
            input_size: æ¨¡å‹è¾“å…¥å°ºå¯¸ (width, height)
        """
        self.conf_threshold = conf_threshold
        self.iou_threshold = iou_threshold
        self.input_width, self.input_height = input_size

        log.debug("ğŸ”§ æ­£åœ¨åˆå§‹åŒ– YOLO ONNX æ£€æµ‹å™¨...")

        # åˆ›å»º ONNX Runtime ä¼šè¯
        providers = ["CPUExecutionProvider"]
        try:
            self.session = ort.InferenceSession(onnx_path, providers=providers)
        except Exception as e:
            raise ValueError(f"æ— æ³•åŠ è½½ ONNX æ¨¡å‹: {e}")

        # è·å–æ¨¡å‹ä¿¡æ¯
        self.input_name = self.session.get_inputs()[0].name
        self.output_names = [output.name for output in self.session.get_outputs()]

        # å¦‚æœæä¾›äº†è¾“å…¥å°ºå¯¸ï¼Œä½¿ç”¨æä¾›çš„å°ºå¯¸
        if input_size != (640, 640):
            model_input_shape = self.session.get_inputs()[0].shape
            if len(model_input_shape) == 4:
                self.input_height = model_input_shape[2]
                self.input_width = model_input_shape[3]

        # ç±»åˆ«åç§°
        self.class_names = class_names or ["object"]  # é»˜è®¤ç±»åˆ«

        log.debug("âœ… YOLO ONNX æ£€æµ‹å™¨åˆå§‹åŒ–æˆåŠŸ")
        log.debug(f"   è¾“å…¥å°ºå¯¸: {self.input_width}x{self.input_height}")
        log.debug(f"   ç±»åˆ«æ•°é‡: {len(self.class_names)}")
        log.debug(f"   ç±»åˆ«åˆ—è¡¨: {self.class_names}")

    # ==================== å›¾åƒé¢„å¤„ç†æ–¹æ³• ====================

    def _preprocess_image(self, image: np.ndarray) -> tuple:
        """
        é€šç”¨å›¾åƒé¢„å¤„ç†

        Args:
            image: è¾“å…¥å›¾åƒ (BGRæ ¼å¼)

        Returns:
            tuple: (é¢„å¤„ç†åçš„tensor, åŸå§‹å›¾åƒ, åŸå§‹å°ºå¯¸)
        """
        if image is None:
            raise ValueError("è¾“å…¥å›¾åƒä¸ºç©º")

        original_image = image.copy()
        original_height, original_width = image.shape[:2]

        # è°ƒæ•´å°ºå¯¸
        resized = cv2.resize(image, (self.input_width, self.input_height))

        # å½’ä¸€åŒ–
        normalized = resized / 255.0

        # BGR -> RGB
        rgb_image = normalized[:, :, ::-1]

        # (H, W, C) -> (C, H, W)
        channel_first = np.transpose(rgb_image, (2, 0, 1))

        # (C, H, W) -> (1, C, H, W)
        batched = np.expand_dims(channel_first, axis=0)

        # è½¬æ¢ä¸º float32
        input_tensor = batched.astype(np.float32)

        return input_tensor, original_image, (original_width, original_height)

    # ==================== åå¤„ç†æ–¹æ³• ====================

    def _postprocess_detections(self, outputs: List[np.ndarray], original_shape: tuple) -> List[Dict]:
        """
        åå¤„ç†æ£€æµ‹ç»“æœ

        Args:
            outputs: æ¨¡å‹è¾“å‡º
            original_shape: åŸå§‹å›¾åƒå°ºå¯¸ (width, height)

        Returns:
            List[Dict]: æ£€æµ‹ç»“æœåˆ—è¡¨
        """
        predictions = outputs[0]

        # å¤„ç† YOLO è¾“å‡ºæ ¼å¼ (1, 84, 8400) -> (8400, 84)
        if len(predictions.shape) == 3:
            predictions = np.squeeze(predictions, 0).T

        boxes = predictions[:, :4]  # x_center, y_center, width, height
        scores = predictions[:, 4:]  # ç±»åˆ«åˆ†æ•°

        # æ‰¾åˆ°æœ€å¤§åˆ†æ•°å’Œç±»åˆ«
        class_ids = np.argmax(scores, axis=1)
        confidences = np.max(scores, axis=1)

        # è¿‡æ»¤ä½ç½®ä¿¡åº¦
        keep_indices = confidences > self.conf_threshold
        boxes = boxes[keep_indices]
        confidences = confidences[keep_indices]
        class_ids = class_ids[keep_indices]

        if len(boxes) == 0:
            return []

        # NMS å»é‡
        boxes_list = []
        for box in boxes:
            x_center, y_center, width, height = box
            x1 = x_center - width / 2
            y1 = y_center - height / 2
            boxes_list.append([x1, y1, width, height])

        indices = cv2.dnn.NMSBoxes(boxes_list, confidences.tolist(), self.conf_threshold, self.iou_threshold)

        # è½¬æ¢åæ ‡ä¸ºåŸå§‹å›¾ç‰‡åæ ‡
        detections = []
        orig_width, orig_height = original_shape

        for idx in indices:
            i = idx[0] if isinstance(idx, (np.ndarray, list)) else idx

            x_center, y_center, width, height = boxes[i]
            confidence = confidences[i]
            class_id = class_ids[i]

            # è½¬æ¢ä¸ºç»å¯¹åæ ‡
            x_center_abs = x_center * orig_width
            y_center_abs = y_center * orig_height
            width_abs = width * orig_width
            height_abs = height * orig_height

            # è®¡ç®—è¾¹ç•Œæ¡†
            x1 = int(x_center_abs - width_abs / 2)
            y1 = int(y_center_abs - height_abs / 2)
            x2 = int(x_center_abs + width_abs / 2)
            y2 = int(y_center_abs + height_abs / 2)

            # ç¡®ä¿åæ ‡åœ¨èŒƒå›´å†…
            x1 = max(0, min(x1, orig_width - 1))
            y1 = max(0, min(y1, orig_height - 1))
            x2 = max(0, min(x2, orig_width - 1))
            y2 = max(0, min(y2, orig_height - 1))

            class_name = self.class_names[class_id] if class_id < len(self.class_names) else f"class_{class_id}"

            detections.append(
                {
                    "box": [x1, y1, x2, y2],
                    "confidence": float(confidence),
                    "class_id": int(class_id),
                    "class_name": class_name,
                    "center": (int(x_center_abs), int(y_center_abs)),
                }
            )

        return detections

    # ==================== ä¸»è¦æ£€æµ‹æ–¹æ³• ====================

    def detect_image(self, image_source: Union[str, np.ndarray]) -> tuple:
        """
        é€šç”¨æ£€æµ‹æ–¹æ³• - æ”¯æŒå¤šç§è¾“å…¥æº

        Args:
            image_source: å›¾åƒæºï¼Œå¯ä»¥æ˜¯:
                         - å›¾ç‰‡æ–‡ä»¶è·¯å¾„ (str)
                         - numpyæ•°ç»„ (np.ndarray)

        Returns:
            tuple: (ç»“æœå›¾åƒ, æ£€æµ‹ç»“æœåˆ—è¡¨, æ¨ç†æ—¶é—´ms)
        """
        image_array = None
        source_type = "unknown"

        # å¤„ç†ä¸åŒç±»å‹çš„è¾“å…¥æº
        if isinstance(image_source, str):
            # å›¾ç‰‡æ–‡ä»¶è·¯å¾„
            source_type = "file"
            image_array = cv2.imread(image_source)
            if image_array is None:
                raise ValueError(f"æ— æ³•è¯»å–å›¾ç‰‡æ–‡ä»¶: {image_source}")

        elif isinstance(image_source, np.ndarray):
            # numpyæ•°ç»„
            source_type = "array"
            image_array = image_source

        else:
            raise ValueError(f"ä¸æ”¯æŒçš„è¾“å…¥ç±»å‹: {type(image_source)}")

        log.debug(f"ğŸ¯ æ£€æµ‹æ¥æº: {source_type}")

        # é¢„å¤„ç†
        input_tensor, original_image, original_shape = self._preprocess_image(image_array)

        # æ¨ç†
        start_time = time.time()
        outputs = self.session.run(self.output_names, {self.input_name: input_tensor})
        inference_time = (time.time() - start_time) * 1000

        # åå¤„ç†
        detections = self._postprocess_detections(outputs, original_shape)

        # ç»˜åˆ¶ç»“æœ
        result_image = self._draw_detections(original_image, detections)

        return result_image, detections, inference_time

    def detect_batch(self, image_sources: List[Union[str, np.ndarray, int]]) -> List[tuple]:
        """
        æ‰¹é‡æ£€æµ‹

        Args:
            image_sources: å›¾åƒæºåˆ—è¡¨

        Returns:
            List[tuple]: æ¯ä¸ªå›¾åƒçš„æ£€æµ‹ç»“æœ
        """
        results = []
        for i, source in enumerate(image_sources):
            log.debug(f"\nğŸ“¦ å¤„ç†ç¬¬ {i+1}/{len(image_sources)} ä¸ªå›¾åƒ...")
            try:
                result = self.detect_image(source)
                results.append(result)
            except Exception as e:
                log.debug(f"âŒ å¤„ç†ç¬¬ {i+1} ä¸ªå›¾åƒå¤±è´¥: {e}")
                results.append((None, [], 0))
        return results

    # ==================== å·¥å…·æ–¹æ³• ====================

    def _draw_detections(self, image: np.ndarray, detections: List[Dict]) -> np.ndarray:
        """
        åœ¨å›¾åƒä¸Šç»˜åˆ¶æ£€æµ‹ç»“æœ

        Args:
            image: åŸå§‹å›¾åƒ
            detections: æ£€æµ‹ç»“æœåˆ—è¡¨

        Returns:
            ç»˜åˆ¶äº†æ£€æµ‹ç»“æœçš„å›¾åƒ
        """
        result_image = image.copy()
        colors = [
            (0, 255, 0),  # ç»¿è‰²
            (255, 0, 0),  # è“è‰²
            (0, 0, 255),  # çº¢è‰²
            (255, 255, 0),  # é’è‰²
            (255, 0, 255),  # ç´«è‰²
            (0, 255, 255),  # é»„è‰²
        ]

        for detection in detections:
            x1, y1, x2, y2 = detection["box"]
            confidence = detection["confidence"]
            class_name = detection["class_name"]
            class_id = detection["class_id"]

            color = colors[class_id % len(colors)]

            # ç»˜åˆ¶è¾¹ç•Œæ¡†
            cv2.rectangle(result_image, (x1, y1), (x2, y2), color, 2)

            # ç»˜åˆ¶æ ‡ç­¾
            label = f"{class_name}: {confidence:.2f}"
            label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)[0]

            # æ ‡ç­¾èƒŒæ™¯
            cv2.rectangle(result_image, (x1, y1 - label_size[1] - 10), (x1 + label_size[0], y1), color, -1)

            # æ ‡ç­¾æ–‡æœ¬
            cv2.putText(result_image, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 2)

            # ç»˜åˆ¶ä¸­å¿ƒç‚¹
            center_x, center_y = detection["center"]
            cv2.circle(result_image, (center_x, center_y), 3, color, -1)

        return result_image

    def print_detections(self, detections: List[Dict]):
        """æ‰“å°æ£€æµ‹ç»“æœ"""
        log.debug(f"ğŸ“Š æ£€æµ‹åˆ° {len(detections)} ä¸ªç›®æ ‡:")
        for i, det in enumerate(detections):
            log.debug(f"  ğŸ¯ ç›®æ ‡ {i+1}:")
            log.debug(f"     ç±»åˆ«: {det['class_name']}")
            log.debug(f"     ç½®ä¿¡åº¦: {det['confidence']:.4f}")
            log.debug(f"     ä½ç½®: {det['box']}")
            log.debug(f"     ä¸­å¿ƒç‚¹: {det['center']}")

    def save_result(self, image: np.ndarray, filename: str = "detection_result.jpg"):
        """ä¿å­˜ç»“æœå›¾åƒ"""
        cv2.imwrite(filename, image)
        log.debug(f"ğŸ’¾ ç»“æœå·²ä¿å­˜ä¸º: {filename}")
